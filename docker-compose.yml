services:
  # --- INFRASTRUCTURE ---
  redpanda:
    image: docker.redpanda.com/redpandadata/redpanda:v23.2.14
    container_name: redpanda
    ports:
      - "9092:9092"
      - "19092:19092"
    command:
      - redpanda start
      - --smp 1 
      - --overprovisioned
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      - --advertise-kafka-addr internal://redpanda:9092,external://localhost:19092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      - --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      - --rpc-addr redpanda:33145
      # - --on-access-auth=false
    volumes:
      - redpanda_data:/var/lib/redpanda/data
    healthcheck:
      test: ["CMD-SHELL", "rpk cluster health | grep -E 'Healthy|Unhealthy'"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  createbuckets:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin;
      /usr/bin/mc mb myminio/finance-lake;
      /usr/bin/mc mb myminio/mlflow;
      exit 0;
      "

  # --- COMPUTE ---
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
    volumes:
      - ./src:/app/src
      - ./logs:/app/logs

  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
    volumes:
      - ./src:/app/src
      - ./logs:/app/logs

  spark-streaming:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-streaming
    depends_on:
      redpanda:
        condition: service_healthy
      minio:
        condition: service_healthy
      spark-master:
        condition: service_started
    ports:
      - "4040:4040"
    environment:
      - PYTHONPATH=/app/src
      - SPARK_MODE=standalone
      - SPARK_DRIVER_MEMORY=1G
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
      - KAFKA_BROKER=redpanda:9092
    volumes:
      - ./src:/app/src
      - ./logs:/app/logs
      # NOTE: No ./data volume here! Data goes to MinIO S3.
      # Only mount if you need to persist local MLflow runs to a specific local folder 
      # (but best practice is to point MLflow to S3 too).
      - ./data/mlruns:/app/mlruns 

  scraper:
    build:
      context: .
      dockerfile: Dockerfile.scraper
    container_name: scraper
    depends_on:
      redpanda:
        condition: service_healthy
    environment:
      - KAFKA_BROKER=redpanda:9092
      - PYTHONPATH=/app/src
    volumes:
      - ./src:/app/src
      - ./logs:/app/logs

  dashboard:
    build:
      context: .
      dockerfile: Dockerfile.dashboard
    container_name: dashboard
    ports:
      - "8501:8501"
    environment:
      - PYTHONPATH=/app/src
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - S3_ENDPOINT=http://minio:9000
    depends_on:
      - minio:
        condition: service_healthy
    volumes:
      - ./src:/app/src

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.0
    container_name: mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./data/mlruns:/app/mlruns
    command: mlflow ui --host 0.0.0.0 --port 5000 --backend-store-uri file:///app/mlruns

volumes:
  minio_data:
    driver: local
  redpanda_data:
    driver: local

networks:
  default:
    name: financelake-net